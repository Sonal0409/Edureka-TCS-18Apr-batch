
1. Become root user:

# sudo su -

2. Install git if on AWS ec2 instance

# yum install git -y

Above command not required on edureka Lab.

3. Create a Local repository using GIT

#  mkdir myproject

# cd myproject

# touch index1.html index2.html

# ls

# git init

A local repository will be created

# ls -al

.git folder will be available, which is your local repository.


4. Add the configuration parameters in git, which will later update author and email details in the git commit history

2 variables need to be set

user.name
user.email


# git config --global user.name sonal0409

# git config --global user.email admin@gmail.com

List the configurations:

git config --list

try it latter
==========================
git config --global --unset user.name

git config --global --unset user.email



5. Add the files to the stagging area and commit them to Local repo
=========================================

# git status

# git add <filename> <filename2>

or

git add --all

or

git add .

or

git add *.java *.php

# git status

# git commit -m "adding file index1.html"

Commit all the changes/files in the stagging area

If we want to Choose a file to be commited

git commit -m "adding file index1.html" <filename>

================================================

6. Modify exisitng files and add those changes to local repo
====================================================

Take a file which is in local repo

# git ls-files

# vim index1.html

add any data & save the file

# git status

status of file is modified

To add all the modification and commit them to local repo

# git commit -a -m "added modifications"


7. If some files are not required to be tracked by GIT --> ignore certain files for version control

=================================================

Git provides the concept of gitignore, where in we create a file with the name .gitignore
And we will add names of the files that we dont want to track
This concept is applicable to files which are new and untracked

# vim .gitignore

In this file insert the name of files to be ingores

press i

*.txt
*.php
*.state

:wq

# git status

This concept this applicable to new file(files that are not commited)
It is only for untracked file.


8. How can GIT can ignore changes on tracked files for certian time.

GIT STASHING

============================================

If we have some incomplete work on tracked files, we can stash them in a temporary location and latter we can get them back to working directory

vim index1.html

press i

inster some new data

press esc key
:wq   and then enter key

# git status ==> you will see modiffied file

# git diff index1.html

Stash the modifications

# git stash

you can see the stash in .git==>refs==>stash folder

# git stash list

stash is saved a n array of index

stash name stash@{0}

see what saved in the stash 

# git show stash@{0}

================================================

19-Apr Notes
================================================

# sudo su -

# cd myproject

1. Check the log for commit history

# git log

in this HEAD it is an object in git which represents the latest/recent commit id

# git log --oneline

Check commit history of every commit in a single line

# git show <commid id>
Shows what happened in that commit.

See commits of a particular file:

 git log --graph --all -- index1.html


2. Create a feature branch in git  and switch to the branch

========================================

# git branch

Create a new branch

# git branch feature1

Switch to the new branch

# git checkout feature1

[OR]

Create a new branch and switch to the branch also

# git checkout -b feature2

3. Merge the commits/files of new branch to master

Before merging always switch to the destination branch

# git checkout master

# git merge feature1 master

< git merge sourcebranch destinationbranch>


4. Delete a branch which is not merged with master branch

# git branch -D <branchname>

Delete a branch whose commits have been merged with the master branch

# git branch -d feature1


5. Reset the commit history

# git reset --hard <commitid>

here:

commit id is where the HEAD will point to now.

All the other commits above it will be deleted and the chnages will also be deleted from LR and working directory.

It is a destructive command


6. Rebase merging strategy in GIT (rewind the commit history)

# git branch

you should be on the master branch

Now create a new branch

# git branch feature1

On the master branch create 2  new commits

example of my log on master branch

8bce083 (HEAD -> master) on master branch 2
daa1204 on master branch1
ea61e8e (feature1) added modifications
0a733ed adding file index1.html


Now switch to feature branch and create 2 new commits


example of my log on master branch

9981946 (HEAD -> feature1) on branch
156dc12 done in feature branch
ea61e8e added modifications
0a733ed adding file index1.html


I want to rebase - re organise the base of my feature branch

Make sure you are on feature branch

# git rebase master


The commit history will be as such:

41f5d79 (HEAD -> feature1) on branch
9469e15 done in feature branch
8bce083 (master) on master branch 2
daa1204 on master branch1
ea61e8e added modifications
0a733ed adding file index1.html

=================================================

GITHUB:

==================================================

Login to github.com

============================


Personal access tokens (classic) function like ordinary OAuth access tokens. They can be used instead of a password for Git over HTTPS, or can be used to authenticate to the API over Basic Authentication.

1. Create a personal access token:

 > clcik on user menu which is on the extreme right
 > click on settings in that
 > scroll down, on left side you will see developer settings -- click on it
 > on left side 3 rd option --> personla Access token
 > select tokens(classic)
 > click on generate new token --> click on generate new token classic
 > in note --give token name as token19
 > expiration --> leave as is
 > select scopes --> clcik on repo checkbox
 > scroll down and clcik on generate token
 > the generated token need to be copied safely

Make sure to copy your personal access token now. You wonâ€™t be able to see it again!

token:

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


2. Create a remote repository

3. Connect local repo to remote repo

# git checkout master

# git remote add origin https://github.com/Sonal0409/myproject19Apr.git

# git remote -v 

Remove origin if needed

# git remote rm origin


Push data from local to remote

# git push origin master

username : github
password: token

================================

Create a file in github on master branch and pull the file to merge in local repoisotry master branch


Once file is create don master branch of remote repo

go to local repo

# git checkout master

# git pull origin master

pull will fecth changes and merge them with LR and WD

================================


Clone a remote repository to local machine

# git clone https://github.com/Sonal0409/myproject19Apr.git


Forking - complete
===========================================

Jenkisn Set up

SEE THAT YOU ARE IN ROOT DIRECTORY
# cd
# pwd
************************************
JAVA Installation

SEE THAT YOU ARE IN ROOT DIRECTORY

# sudo amazon-linux-extras install java-openjdk11



On the browser open https://www.jenkins.io/

Go to downloads section

Select centos OS

Go to Ec2 machine and execute commands:

  sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo
  sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key
   yum install jenkins -y

Execute command to start jenkins server:

systemctl start jenkins


systemctl status jenkins

Installation is complete on the server




If your jenkins is not starting and is failed with error: 
*************************************************************
Failed to start jenkins.service: The name org.freedesktop.PolicyKit1 was not provided by any .service files
See system logs and 'systemctl status jenkins.service' for details.

Then install java 11 and restart jenkins

For this execute the following command

sudo amazon-linux-extras install java-openjdk11

After this execute below command:

alternatives --config java

It will show you 2 versions of java on your machine:

FOR 

Enter to keep the current selection[+], or type selection number

Give integer 2 

Restart jenkins

Systemctl restart jenkins

********************************



We need to now  set up jenkins dashboard

For this, take public ip address of ec2 server, copy it and go to your browser and give

publicipaddress:8080

On the ec2 server, execute below command

$ cat /var/lib/jenkins/secrets/initialAdminPassword

Copy the password and paste in the browser (jenkins)

Click on continue

Click on Jenkins suggested plugin tab(on left side)

On the next page

Username: admin
Password : admin
Retype password: admin
Email: admin@gmail.com

Click on continue

Click on finish

You will be on the jenkins dashboard



==============================================

jenkisn set up on edureka lab

java -version



 curl -fsSL https://pkg.jenkins.io/debian-stable/jenkins.io-2023.key | sudo tee /usr/share/keyrings/jenkins-keyring.asc > /dev/null

Then add a Jenkins apt repository entry:
    
  echo deb [signed-by=/usr/share/keyrings/jenkins-keyring.asc] https://pkg.jenkins.io/debian-stable binary/ | sudo tee /etc/apt/sources.list.d/jenkins.list > /dev/null

Update your local package index, then finally install Jenkins:


    
 sudo apt-get update
 sudo apt-get install jenkins -y

systemctl start jenkins

==========================================

Jenkins Demo:

1. Create a Freestyle job in jenkins

2. Create a freestyle job and integrate it with GITHUB repostitory

Demo 1: Create a Jenkisn job that will clone a github repository in jenkins workspace

Create a new job in jenkins
Click on + sign to create new item/job/project
Give a name to the job : CloneRepo
Select freestyle project and click on OK button
On the project click on Source code management
Select git option
Give git hub repo path
https://github.com/Sonal0409/myproject05Aug

Branch name as ===>  Master

Save the job

Click on Build now

Repository will be cloned in jenkins workspace

You can go to job â†’ workspace folder to see the files

3. Create a frestyle job and integrate it with Maven

MAVEN : 

> It is a powerful tool which helps in building, managing and documenting your project

> Maven by heart is a plugin based tool

> whenever a maven plugin or command is executed, its output will be stored in folder called target

> It has 2 types of plugins:

build plugins:

Task  						Plugin					GOAL/Commands 	output

Compile the code  			Compiler				mvn compile		class files

execute some Testcases		Surefire				mvn test		test passed/failed status

Package the code			package					mvn package     .war file

Clean the previous build	clean					mvn clean		clean up from target folder
files

Deploy artifact on 			deploy					mvn deploy
artifactory

install all dependencies	install					mvn install


In maven multiple goals can be executed together

# mvn clean install package

Reporting plugins:
==============================
Will always generate reports, and in maven the reports are mostly generated in the format : xml,html,txt

Task  						Plugin					GOAL/Commands 	output

Code Review					pmd						mvn pmd:pmd		pmd.xml report	

test reports				surefire				mvn test		surefire reports - xml,txt

Code coverage				JACOCO,sonarcube		mvn sonar:sonar



Structure MAVEN project

src/main/java   ==> source code will be present
src/test/java   ==> test cases will be present

pom.xml   ==> heart of maven project

 1. dependencies   ==> tools downloded by developer to write code
 2. plugin information

Demo 3: Jenkins + maven integration:

Jenkins--> Manage Jenkins-->Global Tool configuration



Under GIT==> leave it same 

Under maven ==> lets install it automatically
Type mymaven and check the install automatically box.
Save the changes


**********************************
Job Package Job
***************************

Go to jenkins--> new item--> Name= Package==> freestyle project
==> source codemanagement==>select git==> give git repo name https://github.com/Sonal0409/DevOpsClassCodes
 
build ==> invoke top level maven target==>mymaven

 goal = clean install package

==> save==> build now
==> click on build number and see the console

==> go to workspace ==> target/addressbook.war

==========================================================================

pipelines Using plugins are called as Plugin based pipelines or Upstream and downstream pipelines
These pipelines are created using freestyle jobs.

Jenkins allows us to create multiple task in one single job.

Whenever a user has to perfom set of tasks one after other (in a sequence) or in parallel, it can easily be done using 
pipleine template in jenkins

Pipleines in jenkins are nothing but set of task executed in sequence(by default) 

When a user is creating a pipeline we will have to write code for it.
The pipeline code is based on Groovy scripting which is Domain specific lanaguage
In jenkins pipeline code using 2 types of syntax

 > scripted pipeline syntax

> scripted pipeline syntax always starts with a keyword called as node
> When Jenkins version1 came in to the market, the admin used scripted pipeline syntax to write pipeline code
> scripted pipeline syntax is difficult to read and write.
> there is no structure or no definite style which writitng the code
> The code written scripted pipeline syntax is not validated by jenkins
> This syntax is no longer used
> if the pipeline fails, you have to run the pipeline from the begining

 > Declarative pipeline syntax

> Declarative pipeline syntax always starts with a keyword called as pipeline
> With jenkins version2, Declarative pipeline syntax was introduced
>This is well structured syntax, where user is provided with definite pipeline sections
> we need to just declare the pipeline code
> It declarative in nature, syntax is very simple
> if the pipeline failes, you can restart the pipeline form the point that it had failed previously
> Stages in pipeline means Job to be executed
> Every stage will have a Name in the pipeline, steps to be executed, post build steps, 
> jenkins provides a pipeline code snippet generator, that helps your to learn pipeline scripting

Syntax:  key 'value' 
for example: name 'Jenkins'
             sh 'echo "hello All"'

Structure of Declarative pipeline syntax

=========================================

pipeline{

  tools{
		// declare names of tools that will while executing pipeline tasks
}

parameters{

}
agent {
// this is mandatory
// which server the pipleline will be executed
}

stages{
  stage('job1'){
	steps{
		//clone a repo
       }
}
stage('job2'){
	steps{
		sh 'mkdir myfiles'
 		sh 'cd myfiles'
        sh 'mvn compile'
       }
}
stage('job3'){
	steps{
		//clone a repo
       }
}

}

}

==============================

pipeline{
    
    tools{
        maven 'mymaven'
    }
   // in agent any = any available server 
    agent any
   stages{
       stage('Clone a Repo'){
           steps{
               git 'https://github.com/Sonal0409/DevOpsCodeDemo.git'
           }
       }
       
       stage('Compile the code'){
           steps{
               sh 'mvn compile'
           }
       }
       
       stage('CodeReview'){
           steps{
               sh 'mvn pmd:pmd'
           }
       }
       
       stage('Unit Test'){
           steps{
               sh 'mvn test'
           }
       }
       
       stage('Package'){
           steps{
               sh 'mvn clean install package'
           }
       }
       }
}




Parallel stages

pipeline{
    
    tools{
        maven 'mymaven'
    }

    agent any

   stages{
       stage('Clone a Repo'){
           steps{
               git 'https://github.com/Sonal0409/DevOpsCodeDemo.git'
           }
       }

      stage('parallel stage') {

      parallel {

       	stage('Compile the code'){
          	 steps{
              	 sh 'mvn compile'
          	 }
      	 }
       
       stage('CodeReview'){
           	steps{
               sh 'mvn pmd:pmd'
           }
       }
    }
  }
 }
}
======================================

pipeline {
    agent any
    stages {
        stage('job1') {
            steps {
                sh 'mkdir sonal'
            }
        }
        stage('job2') {
            steps {
                catchError(buildResult: 'SUCCESS', stageResult: 'FAILURE') {
                    sh "mkdir sonal"
                }
            }
        }
        stage('job3') {
            steps {
                sh 'touch myfile'
            }
        }
    }
}

============================================================

1. It is better that you write your pipeline code in Github, so that many team members can collaborate to the pipeline
2. it allows version control the changes done on pipelines
3. How does jenkins read pipeline code form github

Using the concept of Jenkinsfile

It is a simple text file. it has no extention 
Name is preffered as Jenkinsfile
This is the file in which we will maintain pipeline code Version control
Jenkins--> pipelinetemplate--> fetch jenkins file--> execute pipeline code for you.
==========================================================

Master and slave Set up

Step 1: create a workder node (VM of type linux) on AWS

Step 2: Install git and java on worker node

# yum install git -y
# sudo amazon-linux-extras install java-openjdk11

Step 3: Create remote root directory on the worker & give permissions for access

/tmp/jenkinsdir
chmod -R 777 /tmp/jenkinsdir

Step 4: Go to master machine and update Jenkins URL

Manage Jenkins> Configure System > update the jenkins URL to the current url > save the page


Step 5: On master machine open Agent port

Manage Jenkins> Configure Global Security> scroll down to agents > select random and save the page

Step 6: Configure worker node on master

Manage Jenkins> Manage nodes and clouds

Number of executors= executor = Job ==> 1
remote root directory : /tmp/jenkinsdir
label : linux_node
Usage: only build jobs with matching labels


Step 7: check if connection is succesfull

Step 8: add agent in the piepline

=========================================================

Continous Deployment with Docker
=====================================================

Install docker in AWS ec2 server

# yum install docker -y

Start docker service

# systemctl start docker
# systemctl status docker

No need to install docker on lab server
================================================



Image Name:

===============================

Registryaddress/repository/Imagename:tagname

docker pull tomcat:7

docker pull dockerhub/library/tomcat:latest


Pull images from DockerHub into dockerhost:
======================================

# docker pull ubuntu

# docker pull ubuntu:18.04

Remove an Image:

# docker rmi ubuntu:18.04


Run the image in dockerhost and launch a container

========================================

# docker run ubuntu

Docker list all containers

# docker ps -a




Docker run command options


Using docker command run an OS image -> launch a container--> container status should be up & running
=======================================

Foreground Mode:(-it)
=======================

Whenver we run docker command with foreground mode:

 > A container will be created
 > Container will be up & running
 > user will be logged on to the container

# docker run -it --name cont1 ubuntu

You will be on the container.

Comeout of the container --> keep the container running

Execute CTL pq

Comeout of the container -->  the container should be exited/Stopped

execute  = > exit

Go back into the container:

# docker attach containername/id

Restart a exited container:

# docker start containername/id


Delete a container:

 docker rm -f cont1

Delete Images and stopped containers:

 docker system prune --all

Using docker command run an webserver image -> launch a container--> container status should be up & running
=======================================

Detached Mode:(-d)
=======================

Whenver we run docker command with foreground mode:

 > A container will be created
 > Container will be up & running
 > user will not be attached to the terminal of to the container

# docker run --name n1 -d nginx

===============================

Access app running on the Containers from browser of the machine


Port Forwarding OR Port Mapping:
===================================

By default an application on docker container is avaibale on its exposed port.

It is the users internet that cannot reach the container port

For this we have do port forwarding or mapping

i.e. we have to map a EC2 free system port with container port

example = 8989:80

systemport:containerport

> If a container is already created, we cnanot do port forwarding for the container

> port forwarding will be applied at the docker run comamnd itself

> flag for port forwarding (-p)

# docker run --name web1 -d -p 8989:80 nginx


> if you want docker to do port mapping then use flag -P



# docker run --name web2 -d -P httpd

=============================================

Docker Volumes:

It is a concept in which we preserve the data of container in the volumes created on docker host

Whenver a containe ris deleted, the data in the container is also lost. In order to overcome this problem, we have docker volumes

Volumes needs to be mounted on the container directory. whatever is there in the container directory will be preserved on the volume directory

Voluems ar eof 2 types:

- named volume
 in this volume a specific name is given to volume directory and volume is created in docker area (/var/lib/docker)

- bind mount
  in this volume the data of the container can be preserved in any directory of the host machine
there is no name given to the volume

Note that: you can use volume to place/copy files on the container directory also.

Volume mapping has to be done, during container runtime.

Named volumes

1. Create a docker volume that will preserve the data of a container

> Create a named volume

# docker volume ls
# docker volume create myvol

> where is the volume created

# docker volume inspect myvol

/var/lib/docker/volumes/myvol/_data

> mount the volume on the container directory

 docker run -it --name cont1 -v myvol:/tmp ubuntu

> preserve data from contaienr to volume

create some files in container and come out of container

> delete container.. data will be there in volume directory

# docker rm -f cont1

# cd /var/lib/docker/volumes/myvol/_data

=============================================

2. Place files from volume on to a container

> go to volume directory, it will have some files

> create a container and mount the volume

docker run -it --name cont1 -v myvol:/tmp ubuntu

> you will observe volume data is there on contaienr sdirectory


try out latter


create a volume and mount on a container1
store some files on the volume
create container2 mapping same volume
make chnages int eh container directory, you wills ee chnages available on second cont also.

==============================================

Bind Mounts:
===================

In this case, data will be saved on any directory of host machine

I have got source code for webapplication in github

https://github.com/Sonal0409/ecomm.git

we will clone the code in docker host in a directory

we will mount the directory on a container with image httpd

We will access the application on the container form browser of our machine
==============================

Dockerfile
===================================

FROM ubuntu
RUN apt-get update
RUN apt-get install nginx -y
COPY index.html /var/www/html/
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]

build dockerfile into an Image

# docker build -t myimage01 .

# docker images

Push the image in docker hub

# docker login

username of dockerhub:
password

Need to chnage name of the image and add repository name

# docker tag myimage01 sonal04/myimage01

Push the image

# docker push sonal04/myimage01



=================================

CI/Cd pipeline

Code in github repo

https://github.com/Sonal0409/DevOpsCodeDemo.git

Build the code ==> maven ==> addressbook.war

/var/lib/jenkins/workspace/CICDpipeline/target/addressbook.war

build a docker file

FROM tomcat:9
COPY addressbook.war /usr/local/tomcat/webapps
EXPOSE 8080
CMD  ["catalina.sh", "run"]

Chnage the name of image
push to dockerhub
===========================

Create the following pipeline in jenkins

pipeline{
    tools{
        maven 'mymaven'
    }
    agent any
    stages{
        stage('clone repo'){
            steps{
                git 'https://github.com/Sonal0409/DevOpsCodeDemo.git'
            }
        }
        stage('Build Code'){
            steps{
                sh 'mvn package'
            }
        }
        
        
        stage('build Image'){
          
            steps{
                sh 'cp /var/lib/jenkins/workspace/CICDpipeline/target/addressbook.war .'
                sh 'docker build -t myaddressbook .'
            }
        }
        
        stage('push Image'){
            steps{
               withCredentials([string(credentialsId: 'DOCKER_HUB_PASWD', variable: 'DOCKER_HUB_PASWD')]) {
                sh 'docker login -u edu123 -p ${DOCKER_HUB_PASWD}'
                }
                sh 'docker tag myaddressbook edu123/myaddressbook'
                sh 'docker push edu123/myaddressbook'
            }
        }
        
        stage('Deploy container'){
            steps{
                sh 'docker run -d -P edu123/myaddressbook'
            }
        }
    }
}


Before executing the pipleine give jenkins permsision to run docker commands
 chmod 777 /var/run/docker.sock

===================================================================================

Container Orchestration Tool --> Docker SWARM
==================================================================================

Orchestration tools --> works in Cluster mode

Cluster --> 2-3 VM with docker installed on them

SWARM cluster ==> multiple docker host with swarm intitiated in it

1. How to create and set a swarm cluster

Take VM1

# docker swarm init

Copy the token and paste on each worker node

docker swarm join --token SWMTKN-1-6957zh43vwr1azic7tpm3gourojw1p367sp555ae5kghrk4pg5-bgtcc8892ddol39s8pb39jn18 172.31.46.73:2377


Generate the token if needed

docker swarm join-token worker

# docker node ls


2. Create multiple containers (replicas) of an Image and distribute them across the cluster

SERVICE object 

 # docker service create --name svc1 --replicas 4 -p 8282:80 nginx

 # docker service ls
 
 # docker service ps svc1

3. HighAvailability feature of swarm

# docker service ls

# docker service ps svc1

Delete any one the replicas

docker rm -f <containerid>

you will observe that immediatly a new replica has been created.


4. Scale up and scale down the replica count for a service

# docker service rm mySvc1

# docker service scale mysvc=4

# docker service scale mysvc=2

Create Service with Volume

docker service create --name myservice --mount type=volume,source=myvolume,target=/mypath --replicas 3 -p 8082:80 nginx

5. Load balacing user requests 

# docker service create --name mysvc --replicas 2 -p 8989:3000 sonal04/samplepyapp:v1

# while true;do curl http://18.188.212.141:8989/;sleep 1;echo " ";done

#  docker service scale mysvc=4
# docker service ls
# docker service update --image sonal04/samplepyapp:v2 mysvc
# docker service rollback mysvc

==================================================================

Kubernetes:
===================

K8s code is written in YAML

YAML syntax is very easy

key: "value"

spacing is important

tool using YAML, will provide you the key or its key name
User has to just give the values

values can be signle value or list of values
values can string, integer, decimal,date

These files have an extension as YAMl or YML

Example: storing single value

---
company: Edureka
training: devops
trainer: sonal mittal
time: 7PM
days: weekdpas
...

Example: storing multiple values in a key

---
company: Edureka
trainings:
  - devops
  - aws
  - gcp
  - selenium
trainers:
  - Sonal
  - Jaya
  - MArc
  - Jack

example: store data as an object

---
company: Edureka
trainings:
  - devops
  - aws
  - gcp
  - selenium
trainers:
  - Name: Sonal
    phone: 979887345
    emial: sdfsdf#dfgdfg
  - Name: Jaya
    phone: 3435345
    email: 43535
timings:
 - weekdays:
    days: mon-friday
 - weekends:
    morning: 7am
    eveinign: 7am


================================

Create a pod in kubernetes:

apiVersion: v1
kind: Pod
metadata:
  name: pod1
  labels:
    author: sonal
    env: dev
    app: webserver
spec:
 containers:
  - name: c1
    image: nginx

================================

MultiContainer Pod

apiVersion: v1
kind: Pod
metadata:
  name: pod1
  labels:
    author: sonal
    env: dev
    app: webserver
spec:
 containers:
  - name: c1
    image: nginx
  - name: c2
    image: tomcat
  - name: c3
    image: ubuntu
    command: ["bash","-c", "sleep 6000"]



































































































































































































































































































































































































































































































































































































































 




























































































































































































































































